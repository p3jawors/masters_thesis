{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learned Legendre Predictor\n",
    "Terry Stewart, Andreas Stoeckel, Chris Eliasmith\n",
    "\n",
    "## Overall goal:\n",
    "\n",
    "I want to predict the future state of some system, based on the current state and other context information.  For example, predict the future state of a robot arm based on its current state and the context of what commands have been sent to the robot arm recently.  I want this prediction to be across a window of time (e.g., not just predicting what the values will be exactly 10ms into the future, but instead a prediction for the entire window of time between 0 and $\\theta$ seconds into the future).  Most importantly, I want to continue to improve this prediction all the time based on the new data coming in, at the same time as I am using this prediction to perform some task (e.g., controlling the robot arm to go to some position).\n",
    "\n",
    "## Current approaches\n",
    "\n",
    "Right now, this can be done with online training of a neural network.  The input to the neural network is the current state and context information, and the output is the predicted future state at many points in time in the future.  When the new data is observed, we use a standard neural network backpropagation learning rule to adjust the network to be better at prediction.\n",
    "\n",
    "One limitation of current approaches is that, for the output prediction, we have to pick a set of time points in the future at which to make predictions.  This discretizes the prediction.  However, a more important limitation is that in order to implement the standard backpropagation learning algorithm, we need to be feeding the old information into the network.  That is, if I am predicting behaviour 500ms into the future, then I need to compare the behaviour I currently observe to the value that the network predicted 500ms in the past.  This means that I have to store the old state of the network (including the old activities of the neurons) in order to run the learning rule.  This in turn means that, rather than having one neural network doing both prediction and learning, I need to have two neural networks: one that is getting the current input and is making predictions about the future, and one that is getting the old input and is learning to improve its predictions.  These neural networks would have the same connection weights (so that whatever the learning one learns is used be the one doing prediction).  This sort of weight sharing is efficient on some compute hardware (such as GPUs), but in many of the new generation of “neuromorphic” computer hardware, this sort of weight sharing is not possible (and, indeed, removing this sort of weight sharing is a big part of why neuromorphic computing hardware is more energy efficient).  It is also worth noting that the brain seems to perform this sort of learning without doing weight sharing.\n",
    "\n",
    "Finally, current approaches discretize time immediately while the system being proposed is fully specified in continuous time (and space). While the proposed system is typically implemented in discrete time (as it runs on a digital computer), by adopting a 'continuity first' approach it results in a more tunable system (i.e., more tunable to the specifics of the discretization required).\n",
    "\n",
    "## New invention\n",
    "\n",
    "The invention here is to a) compress the predictions about the future into a temporal basis space, b) compress the stored information about past predictions and past neural activities into the Legendre temporal basis space, and c) define a new neural network learning rule that acts directly in that compressed space. The most novel aspect of this invention is the learning rule.  We're using the Legendre space because there’s an efficient way of getting a linear neural network to do that conversion, although other spaces are also possible.  \n",
    "\n",
    "We give the derivation below for the Learned Legendre Predictor.  This is a single-hidden-layer neural network, and here we only learn the second layer of weights and have no non-linearity at the output.  Extensions could be made to also adjust the first layer of weights (in a manner akin to the classic back-propagation learning algorithm), but here instead we initialize those weights randomly using any existing method and leave them fixed.\n",
    "\n",
    "We show the utility of this invention by applying it to a controller with delay. In general, it applies to any system that requires prediction of future information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivation of the Learned Legendre Predictor\n",
    "\n",
    "### Definitions\n",
    "\n",
    "- $\\vec{c}(t)$: the context vector (any information we are using as input to create the prediction)\n",
    "- $\\vec{z}(t)$: the vector to predict (m-dimensional, usually a subset of $\\vec{c}(t)$)\n",
    "- $\\vec{a}(t)$: the activity of the neurons representing the context ($N$ dimensional)\n",
    "\n",
    "- $q$: number of (shifted) Legendre polynomials to use for predicting the future\n",
    "- $\\theta$: the window size for the prediction\n",
    "- $Z(t)$: the prediction of the next $\\theta$ seconds, at time $t$ ($q\\times m$ dimensional), using Legendre representation\n",
    "- $D(t)$: the decoder weights (the connection weights from the hidden layer neurons to the output) ($N \\times q \\times m$)\n",
    " - Note: since this is now a tensor, so we can use Einstein tensor notation to write all this.  As an example, here is the notation for computing the output prediction $Z$ from the network, given the hidden layer neural activities $\\vec{a}$ and the output connection weights $D$:\n",
    "   - $Z_{qm}(t)=\\vec{a}_N(t)D^N_{qm}(t)$\n",
    " - which means this, where $i$ and $j$ are index variables across $q$ and $m$, respectively.  In other words,\n",
    "   - $Z[i,j](t)=\\sum_N\\vec{a}[N](t)D[N,i,j](t)$\n",
    "- $\\mathcal{P}(\\tau)$: the vector of $q$ (shifted) Legendre polynomials, evaluated at $\\tau$ (the LDN uses Legendre polynomials that have been shifted to the domain (0,1) rather than the typical (-1,1) domain).\n",
    "\n",
    "### Approach\n",
    "\n",
    "The basic approach for the derivation is to start with the classic delta learning rule (the basis for all neural network learning algorithms, including backpropagaion).  With a normal delta learning rule, you can learn to predict the future by:\n",
    "\n",
    "- delaying your predicted output before using it to compute the error\n",
    "- using the activity from the past\n",
    "\n",
    "In other words, instead of\n",
    "\n",
    "- $\\Delta D(t) = -\\kappa \\vec{a}(t) \\times (\\vec{\\hat{z}}(t)-\\vec{z}(t))$\n",
    "- (or, in Einstien notation: $\\Delta D^N_m(t) = -\\kappa a(t)^N (\\hat{z}_m(t)-z_m(t))$\n",
    "\n",
    "we do\n",
    "\n",
    "- $\\Delta D(t) = -\\kappa \\vec{a}(t-\\tau) \\times (\\vec{\\hat{z}}(t-\\tau)-\\vec{z}(t))$\n",
    "- (or, in Einstien notation: $\\Delta D^N_m(t) = -\\kappa a^N(t-\\tau) (\\hat{z}_m(t-\\tau)-z_m)$\n",
    "\n",
    "\n",
    "But, what we would really like to do is to make and learn predictions for all values of $\\tau$ (within some window $\\theta$), and to do this all at once.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, instead of assuming we have perfect delays everywhere, we need LDN representations of the prediction $Z(t)$ and of the activity $\\vec{a}(t)$.  These LDNs can have their own $q$ values, but should have the same $\\theta$ as the prediction window.\n",
    "- $q_p$: the $q$ value for the prediction memory\n",
    "- $M(t)$: ($m \\times q \\times q_p$) tensor that is an LMU for each element in $Z(t)$\n",
    "- $q_a$: the $q$ value for the activity memory\n",
    "- $A(t)$: ($N \\times q_a$) matrix that is an LMU for the activity of each neuron in $\\vec{a}(t)$\n",
    "\n",
    "Importantly, note that $M$ is now an LDN of a Legendre representation!  That is, the output from the network is $Z$, which is a Legendre representation of the predicted behaviour of the system over a window in time $\\theta$.  We take those predicted coeffecients and feed them into an LDN to produce $M$, which is the past history (over the last $\\theta$ seconds) of our predictions of the behaviour from now to $\\theta$ seconds into the future.\n",
    "\n",
    "To get the activity delayed by $\\tau$, we can decode that out of the LMU for activity\n",
    "\n",
    "- $\\vec{a}(t-\\tau) \\approx  A(t) \\mathcal{P}(\\tau)$ (matrix notation)\n",
    "- $\\vec{a}(t-\\tau)^N \\approx  A^N_{q_a}(t) \\mathcal{P}(\\tau)^{q_a}$ (Einstein notation)\n",
    "\n",
    "To get the prediction for $\\tau$ into the future, but delayed by $\\tau$, we can read that out of $M$ by decoding twice:\n",
    "\n",
    "- $\\vec{z}_{predict, \\tau}(t-\\tau) \\approx  \\mathcal{P}(\\tau)^T M(t)\\mathcal{P}(\\tau)$ (matrix notation, but assuming $m=1$ so that $M$ is a matrix, rather than a tensor which it actually is)\n",
    "\n",
    "- $\\vec{z}_{predict, \\tau}(t-\\tau)_m \\approx  \\mathcal{P}(\\tau)_{q_p} M(t)^{q_p}_{m q}\\mathcal{P}(\\tau)^{q}$ (Einstein notation, which we're going to use from here on)\n",
    "\n",
    "From that, we can generate our error by subtracting from $\\vec{z}(t)$.  But that's not the error for the function we're learning!  Our output needs to represent $Z(t)$, so we also need to project our error back into the LMU space.  We need a new indexing variable for this, so we'll use $q_r$ (for *result*), but it will always be $q_r = q$.\n",
    "\n",
    "- $\\bigg(\\mathcal{P}(\\tau)_{q_p} M(t)^{q_p}_{m q}\\mathcal{P}(\\tau)^{q} - z_m(t)\\bigg)\\mathcal{P}(\\tau)_{q_r}$\n",
    "\n",
    "Except that's not quite right either, since the Legendre polynomials are not an orthonormal space.  They are orthogonal, but not normalized.  So we need a scaled version of them.  The scaling factor is $2i+1$, so we define $S_{q_r}^{q_r}$ as a ${q_r} \\times {q_r}$ diagonal matrix with $S[i,i] = 2i+1$.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for one particular $\\tau$, our learning rule is:\n",
    "\n",
    "- $\\Delta D(t)^N_{q_r m} = -\\kappa A^N_{q_a}(t) \\mathcal{P}(\\tau)^{q_a} \\bigg(\\mathcal{P}(\\tau)_{q_p} M(t)^{q_p}_{m q}\\mathcal{P}(\\tau)^{q} - z_m(t)\\bigg)\\mathcal{P}(\\tau)_{q_r} S_{q_r}^{q_r}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating over time\n",
    "\n",
    "\n",
    "But, we want to have the system learn at all $\\tau$ values inside the $\\theta$ window. So, we integrate:\n",
    "\n",
    "- ${\\displaystyle\\Delta D(t)^N_{q_r m} =  \\int_0^1 -\\kappa A^N_{q_a}(t) \\mathcal{P}(\\tau)^{q_a} \\bigg(\\mathcal{P}(\\tau)_{q_p} M(t)^{q_p}_{m q}\\mathcal{P}(\\tau)^{q} - z_m(t)\\bigg)\\mathcal{P}(\\tau)_{q_r} S_{q_r}^{q_r} d\\tau }$\n",
    "\n",
    "\n",
    "Let's do some rearranging\n",
    "\n",
    "- ${\\displaystyle\\Delta D(t)^N_{q_r m} =  -\\kappa A^N_{q_a}(t) \\int_0^1 \\mathcal{P}(\\tau)^{q_a} \\bigg(\\mathcal{P}(\\tau)_{q_p} M(t)^{q_p}_{m q}\\mathcal{P}(\\tau)^{q} - z_m(t)\\bigg)\\mathcal{P}(\\tau)_{q_r} S_{q_r}^{q_r} d\\tau }$\n",
    "\n",
    "- ${\\displaystyle\\Delta D(t)^N_{q_r m} =  -\\kappa A^N_{q_a}(t) \\int_0^1 \\mathcal{P}(\\tau)^{q_a} \\mathcal{P}(\\tau)_{q_p} M(t)^{q_p}_{m q}\\mathcal{P}(\\tau)^{q}\\mathcal{P}(\\tau)_{q_r} S_{q_r}^{q_r} - \\mathcal{P}(\\tau)^{q_a} z_m(t)\\mathcal{P}(\\tau)_{q_r} S_{q_r}^{q_r} d\\tau }$\n",
    "\n",
    "- ${\\displaystyle\\Delta D(t)^N_{q_r m} =  -\\kappa A^N_{q_a}(t) \\bigg( \\int_0^1 \\mathcal{P}(\\tau)^{q_a} \\mathcal{P}(\\tau)_{q_p} M(t)^{q_p}_{m q}\\mathcal{P}(\\tau)^{q}\\mathcal{P}(\\tau)_{q_r} S_{q_r}^{q_r}d\\tau - \\int_0^1\\mathcal{P}(\\tau)^{q_a} z_m(t)\\mathcal{P}(\\tau)_{q_r} S_{q_r}^{q_r} d\\tau } \\bigg)$\n",
    "\n",
    "Since $M$ and $z$ are not dependent on $\\tau$, we can pull them out of the integral.\n",
    "\n",
    "- ${\\displaystyle\\Delta D(t)^N_{q_r m} =  -\\kappa A^N_{q_a}(t) \\bigg( M(t)^{q_p}_{m q} \\int_0^1 \\mathcal{P}(\\tau)^{q_a} \\mathcal{P}(\\tau)_{q_p} \\mathcal{P}(\\tau)^{q}\\mathcal{P}(\\tau)_{q_r} S_{q_r}^{q_r}d\\tau - z_m(t) \\int_0^1\\mathcal{P}(\\tau)^{q_a} \\mathcal{P}(\\tau)_{q_r} S_{q_r}^{q_r} d\\tau } \\bigg)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we do with these integrals?\n",
    "\n",
    "Well, the second one is really pretty.  \n",
    "\n",
    "$\\int_0^1\\mathcal{P}(\\tau)^{q_a} \\mathcal{P}(\\tau)_{q_r} S_{q_r}^{q_r} d\\tau$\n",
    "\n",
    "That's the integral of two Legendre polynomials multiplied with each other across their entire size (remember we're dealing with shifted Legendre polynomials here, so the limits are 0 to 1, not -1 to 1 as would be standard).  Since they're orthogonal, all the off-diagonals must be 0.  The elements along the diagonal are the Legendre polynomials multiplied by themselves, along with a nice convenient scaling factor.\n",
    "\n",
    "So that means this is just the identity matrix!  \n",
    "\n",
    "Well, if $q_r = q_a$ it's the identity matrix.  Otherwise it's a $q_r \\times q_a$ chunk of the identity matrix.\n",
    "\n",
    "$\\int_0^1\\mathcal{P}(\\tau)^{q_a} \\mathcal{P}(\\tau)_{q_r} S_{q_r}^{q_r} d\\tau = \\delta^{q_a}_{q_r}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the second one?  We can at least pull out $S_{q_r}^{q_r}$ and we're left with\n",
    "\n",
    "$Q^{q_a q}_{q_p q_r} = \\int_0^1 \\mathcal{P}(\\tau)^{q_a} \\mathcal{P}(\\tau)_{q_p} \\mathcal{P}(\\tau)^{q}\\mathcal{P}(\\tau)_{q_r}d\\tau$\n",
    "\n",
    "This is a $q_a \\times q \\times q_p \\times q_r$ tensor, where each element is the result of computing the integral of four Legendre polynomials multiplied together.  This tensor is not dependent on any observation, so it can be precomputed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from numpy.polynomial.legendre import Legendre\n",
    "\n",
    "def generate_quad_integrals(q):\n",
    "    def quad(i, j, m, n):\n",
    "        li, lj, lm, ln = (Legendre([0] * k + [1]) for k in (i, j, m, n))\n",
    "        L = (li * lj * lm * ln).integ()\n",
    "        # the desired result is (L(1) - L(-1)) / 2 (as this is for non-shifted Legendre)\n",
    "        #  but since L(1) == -L(-1), this is just L(1)\n",
    "        return L(1)  \n",
    "\n",
    "    w = np.zeros((q, q, q, q))\n",
    "    for i in range(q):\n",
    "        for j in range(i, q):\n",
    "            for m in range(j, q):\n",
    "                for n in range(m, q):\n",
    "                    # skip indices guranteed to be 0\n",
    "                    if (i+j+m-n >= 0) and ((i+j+m-n) % 2 == 0):\n",
    "                        v = quad(i, j, m, n)\n",
    "                        for index in itertools.permutations([i, j, m, n]):\n",
    "                            w[index] = v\n",
    "    return w\n",
    "\n",
    "q = 6\n",
    "Q = generate_quad_integrals(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(Q.reshape(q*q,q*q), cmap='gray_r')\n",
    "for i in range(q):\n",
    "    plt.axvline(i*q-0.5)\n",
    "    plt.axhline(i*q-0.5)    \n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, once we pre-compute $Q^{q_a q}_{q_p q_r}$ we are left with this learning rule:\n",
    "\n",
    "- $\\Delta D(t)^N_{q_r m} =  -\\kappa A^N_{q_a}(t) \\bigg( M(t)^{q_p}_{m q} Q^{q_a q}_{q_p q_r} S_{q_r}^{q_r}- z_m(t)\\delta^{q_a}_{q_r} \\bigg)$\n",
    "\n",
    "We can also roll $S$ into $Q$ if we want to save a bit of compuation.  The result is a simple linear learning rule that just depends on the current observation $z$ and the contents of the $A$ and $M$ LDNs.\n",
    "\n",
    "This will learn to predict the future trajectory of $z$ across the whole time window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Delta D(t)^N_{q_r m} =  -\\kappa A^N_{q_a}(t) \\bigg( M(t)^{q_p}_{m q} Q^{q_a q}_{q_p q_r} S_{q_r}^{q_r}- z_m(t)\\delta^{q_a}_{q_r} \\bigg)$\n",
    "\n",
    "Combining zd: zd = np.einsum(\"mq, aq->maq\", z, d)\n",
    "$\\Delta D(t)^N_{q_r m} =  -\\kappa A^N_{q_a}(t) \\bigg( M(t)^{q_p}_{m q} Q^{q_a q}_{q_p q_r} S_{q_r}^{q_r}- (z\\delta)^{q_a}_{m q_r} \\bigg)$\n",
    "\n",
    "$\\Delta D(t)^N_{q_r m} =  -\\kappa A^N_{q_a}(t) \\bigg( M(t)^{q_p}_{m q} (QS)^{q_a}_{q_p} - (z\\delta)^{q_a}_{m q_r} \\bigg)$\n",
    "\n",
    "$\\Delta D(t)^N_{q_r m} =  -\\kappa A^N_{q_a}(t) \\bigg( (MQS)^{q_a}_{m q} - (z\\delta)^{q_a}_{m q_r} \\bigg)$\n",
    "\n",
    "$\\Delta D(t)^N_{q_r m} =  -\\kappa A^N_{q_a}(t) \\bigg( (MQS - z\\delta)^{q_a}_{m q_r} \\bigg)$\n",
    "\n",
    "$\\Delta D(t)^N_{q_r m} =  \\bigg(-\\kappa A(MQS - z\\delta) \\bigg)^N_{q_r m}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Application 1: Generalizing P and PD Control to deal with delays and other dynamics\n",
    "\n",
    "On its own, the LLP is just a network that learns to make predictions.  To have those predictions be useful, we need to take the output of the LLP and use it for something.\n",
    "\n",
    "In particular, we note that if we have a prediction of how a motor is going to behave in the near future, then we can make use of that to control it better.  In particular, many motors (and other physical systems) have delays: when you send a signal to the motor, it does not respond immediately, and it instead may have some delay time, and may have some internal dynamics (such as inertia).  If this can be taken into account, then control can be improved.  \n",
    "\n",
    "The simplest way to do this is to use the predicted future value as part of an existing control system.  For example, in standard Proportional control, the signal sent to control a motor is:\n",
    "\n",
    "$u(t) = K_p(z_{desired}(t) - z_{actual}(t))$\n",
    "\n",
    "We could instead use the LLP's predicted future position of the arm $\\tau$ seconds into the future instead of $z_{actual}$:\n",
    "\n",
    "$u(t) = K_p(z_{desired}(t) - Z(t)\\mathcal{P}(\\tau))$\n",
    "\n",
    "Furthermore, since there is also a matrix $\\mathcal{D}$ which computes the derivative of the Legendre polynomials, we can extend this to Proportional Derivative control with:\n",
    "\n",
    "$u(t) = K_p(z_{desired}(t) - Z(t)\\mathcal{P}(\\tau)) + K_d(\\dot z_{desired}(t) - Z(t)\\mathcal{D}\\mathcal{P}(\\tau))$\n",
    "\n",
    "The result is a controller that learns to deal with delays and other dynamics in the system being controlled (as long as that delay is less than $\\tau$).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application 2: Predicting the desired signal as well\n",
    "\n",
    "One problem with Application 1 is that, if it performs correctly, the actual behaviour of the system will be $\\tau$ seconds behind where we want it to be (since the subtraction is between the desired value right now ($z_{desired}(t)$) and the predicted value $\\tau$ seconds from now.  Instead, it would be better to use the desired value $\\tau$ seconds from now.\n",
    "\n",
    "Fortunately, we can do this by just having a separate LLP that learns to predict the future of $z_{desired}$.  This requires no changes to anything in the above derivation: we just have one system that learns the future of the system being controlled ($Z(t)$), and one that learns the future of the desired signal that the motor is supposed to follow ($Z_{desired}(t)$).\n",
    "\n",
    "$u(t) = K_p(Z_{desired}(t)\\mathcal{P}(\\tau) - Z(t)\\mathcal{P}(\\tau))$\n",
    "\n",
    "$u(t) = K_p(Z_{desired} - Z(t))\\mathcal{P}(\\tau))$\n",
    "\n",
    "or, for the PD case, we have\n",
    "\n",
    "$u(t) =  K_p(Z_{desired} - Z(t))\\mathcal{P}(\\tau)) +  K_d(Z_{desired} - Z(t))\\mathcal{D}\\mathcal{P}(\\tau))$\n",
    "\n",
    "\n",
    "\n",
    "indeed, since $K_p$, $\\mathcal{P}(\\tau)$, and $\\mathcal{D}$ are all constant linear values, the whole control system can be collapsed to\n",
    "\n",
    "$u(t) =  (Z_{desired} - Z(t))W$\n",
    "\n",
    "where $W$ is a matrix.  By adjusting $W$, we can have PD control at any point $\\tau$.  Furthermore, we could also have PD control at all points $\\tau$ between 0 and $\\theta$, or we can scale by different weights in order to smoothly emphasize some $\\tau$ values more than others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- While this approach is derived based on Legendre polynomials, other basis spaces would also work and produce similar results\n",
    "- While this derivation considers changing only output weights, extensions using backpropagation to determine input weights are considered as straightforward.\n",
    "- While the derivation considers a single layer network, extension to multiple layers would follow from use of backpropagation.\n",
    "- While the application here is to handling delay in a controlled system, the invention applies to any system requiring temporal prediction.\n",
    "- While the application here is demonstrating online learning to find the predictor, offline learning is a simple extension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
